print("hello")
install.packages("Rcmdr")
quartz()
library("Rcmdr", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
detach("package:Rcmdr", unload=TRUE)
detach("package:RcmdrMisc", unload=TRUE)
library("Rcmdr", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
install.packages("plotrix")
install.packages("plotrix")
myString <- "Hello, World!"
myString
print ( myString)
v <- true
v <- TRUE
v
apple <- c('red','green',"yellow")
apple
apple[1]
apple[1,2]
apple[1..2]
a <- array(c('green','yellow'),dim = c(3,3,2))
a
apple_colors <- c('green','green','yellow','red','red','red','green')
factor_apple <- factor(apple_colors)
factor_apple
print(nlevels(factor_apple))
BMI <- 	data.frame(
gender = c("Male", "Male","Female"),
height = c(152, 171.5, 165),
weight = c(81,93, 78),
Age = c(42,38,26)
)
BMI
ls
ls()
ls(all.name = TRUE)
var.3
var.test()
v <- c( 2,5.5,6)
t <- c(8, 3, 4)
v+t
t <- c(8, 3, 4, 6)
v+t
v <- c(0,0,TRUE,2+2i)
t <- c(0,3,TRUE,2+3i)
v||t
t <- c(0,3,FALSE,2+3i)
v||t
t <- c(0,3,TRUE,2+3i)
v&&t
v <- 2:8
v
x <- c("what","is","truth")
if("Truth" %in% x) {
print("Truth is found")
} else {
print("Truth is not found")
}
if("truth" %in% x) {
print("Truth is found")
} else {
print("Truth is not found")
}
t <- c("Sun","Mon","Tue","Wed","Thurs","Fri","Sat")
u <- t[c(2,3,6)]
u
u <- t[cx <- t[c(-2,-5)]
(2,3,6)]
x <- t[c(-2,-5)]
x
t[1]
x
t
y <- t[c(0,0,0,0,0,0,1)]
y
t
y <- t[c(0,0,0,0,0,0,0)]
y
y <- t[c(1,0,0,0,0,0,0)]
y
emp.data <- data.frame(
emp_id = c (1:5),
emp_name = c("Rick","Dan","Michelle","Ryan","Gary"),
salary = c(623.3,515.2,611.0,729.0,843.25),
start_date = as.Date(c("2012-01-01", "2013-09-23", "2014-11-15", "2014-05-11",
"2015-03-27")),
stringsAsFactors = FALSE
)
result <- emp.data[c(3,5),c(2,4)]
result
result <- emp.data[3,4]
result
emp.data
library(MASS)
ships
molten.ships <- melt(ships, id = c("type","year"))
library(MASS)
molten.ships <- melt(ships, id = c("type","year"))
install.packages("MASS")
molten.ships <- melt(ships, id = c("type","year"))
library("MASS", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
molten.ships <- melt(ships, id = c("type","year"))
molten.ships <- melt(ships, id = c("type","year"))
getwd
getwd()
x <- c(12,7,3,4.2,18,2,54,-21,8,-5)
result.mean <-  mean(x,trim = 0.3)
result.mean
y = c(3, 4.2, 7, 8)
mean(y)
x <- c(21, 62, 10, 53)
labels <- c("London", "New York", "Singapore", "Mumbai")
png(file = "city.jpg")
pie(x,labels)
dev.off()
getwd()
gsfdg
getwd()
df_accel_hour2 <- df_accel %>%
group_by(day, hour) %>%
summarise(nsamples = length(hour),
x.mean = mean(x.mean),
x.absolute.deviation = mean(x.absolute.deviation),
x.standard.deviation = mean(x.standard.deviation),
x.max.deviation = mean(x.max.deviation),
x.PSD.1 = mean(x.PSD.1),
x.PSD.3 = mean(x.PSD.3),
x.PSD.6 = mean(x.PSD.6),
x.PSD.10 = mean(x.PSD.10),
y.mean = mean(y.mean),
y.absolute.deviation = mean(y.absolute.deviation),
y.standard.deviation = mean(y.standard.deviation),
y.max.deviation = mean(y.max.deviation),
y.PSD.1 = mean(y.PSD.1),
y.PSD.3 = mean(y.PSD.3),
y.PSD.6 = mean(y.PSD.6),
y.PSD.10 = mean(y.PSD.10),
z.mean = mean(z.mean),
z.absolute.deviation = mean(z.absolute.deviation),
z.standard.deviation = mean(z.standard.deviation),
z.max.deviation = mean(z.max.deviation),
z.PSD.1 = mean(z.PSD.1),
z.PSD.3 = mean(z.PSD.3),
z.PSD.6 = mean(z.PSD.6),
z.PSD.10 = mean(z.PSD.10)) %>%
filter(nsamples >= 5) %>% # at least 5 seconds of samples
mutate(date = as.POSIXct(day, format = "%Y-%m-%d")) %>%
ungroup() %>%
select(-c(nsamples, day))
clearPushBack()
ggplot(data = accel_data,
aes(x = xyz.PSD.3, y = xyz.PSD.10)) +
geom_point(aes(color = class))
library(dplyr)
library(ggplot2)
library(GGally)
library(MASS)
library(e1071)
library(corrplot)
users = c("APPLE", "CHERRY", "CROCUS", "DAFODIL",
"DAISY", "FLOX", "IRIS", "LILY",
"MAPLE", "ORANGE", "ORCHID", "PEONY", "ROSE",
"SUNFLOWER", "SWEETPEA", "VIOLET")
csv_data = "csv_data"
compress_data = "compress_data"
train_users_csv = file.path(csv_data, "train_users.csv")
df_train_users = read.csv(train_users_csv, stringsAsFactors = FALSE)
f_accuracy = function(pred, actual) {
mean(pred == actual) * 100
}
load(file = file.path(compress_data, paste0("accel_by_hour_xyz_all.rda")))
load(file = file.path(compress_data, paste0("df_gps_day_hour_distance_all.rda")))
f_filter_df_accel = function(gps_day_hour_distance_row) {
print(gps_day_hour_distance_row)
df_accel_by_hour_xyz_all$user == gps_day_hour_distance_row[5] &
as.character(df_accel_by_hour_xyz_all$date) == gps_day_hour_distance_row[1] &
df_accel_by_hour_xyz_all$hour == gps_day_hour_distance_row[2]
}
MAX_DISTANCE_THRESHOLD = 5000
valid_gps_index = df_gps_day_hour_distance_all$max_distance <= MAX_DISTANCE_THRESHOLD
df_valid_gps_distance = df_gps_day_hour_distance_all[valid_gps_index,]
print(paste0("valid gps distance row: ", nrow(df_valid_gps_distance)))
df_accel_filter = NULL
for (i in 1:nrow(df_valid_gps_distance)) {
selected_index = apply(df_valid_gps_distance[i,], 1, f_filter_df_accel)
print(i)
print(sum(selected_index))
selected_rows = df_accel_by_hour_xyz_all[selected_index,]
df_accel_filter = rbind(df_accel_filter, selected_rows)
}
table(df_accel_filter$type)
df_valid_gps_distance = df_gps_day_hour_distance_all[valid_gps_index,]
load(file = file.path(compress_data, paste0("df_gps_day_hour_distance_all.rda")))
setwd("/Users/longnguyen/Documents/295/neuro-analytics/machine_learning")
users = c("APPLE", "CHERRY", "CROCUS", "DAFODIL",
"DAISY", "FLOX", "IRIS", "LILY",
"MAPLE", "ORANGE", "ORCHID", "PEONY", "ROSE",
"SUNFLOWER", "SWEETPEA", "VIOLET")
csv_data = "csv_data"
compress_data = "compress_data"
train_users_csv = file.path(csv_data, "train_users.csv")
df_train_users = read.csv(train_users_csv, stringsAsFactors = FALSE)
f_accuracy = function(pred, actual) {
mean(pred == actual) * 100
}
load(file = file.path(compress_data, paste0("accel_by_hour_xyz_all.rda")))
load(file = file.path(compress_data, paste0("df_gps_day_hour_distance_all.rda")))
f_filter_df_accel = function(gps_day_hour_distance_row) {
print(gps_day_hour_distance_row)
df_accel_by_hour_xyz_all$user == gps_day_hour_distance_row[5] &
as.character(df_accel_by_hour_xyz_all$date) == gps_day_hour_distance_row[1] &
df_accel_by_hour_xyz_all$hour == gps_day_hour_distance_row[2]
}
MAX_DISTANCE_THRESHOLD = 5000
valid_gps_index = df_gps_day_hour_distance_all$max_distance <= MAX_DISTANCE_THRESHOLD
df_valid_gps_distance = df_gps_day_hour_distance_all[valid_gps_index,]
print(paste0("valid gps distance row: ", nrow(df_valid_gps_distance)))
df_accel_filter = NULL
for (i in 1:nrow(df_valid_gps_distance)) {
selected_index = apply(df_valid_gps_distance[i,], 1, f_filter_df_accel)
print(i)
print(sum(selected_index))
selected_rows = df_accel_by_hour_xyz_all[selected_index,]
df_accel_filter = rbind(df_accel_filter, selected_rows)
}
table(df_accel_filter$type)
table(df_accel_filter$user, df_accel_filter$type)
xyz_columns = names(df_accel_filter)[grepl("xyz", names(df_accel_filter))]
df_accel_candidate = data.frame(df_accel_filter[, names(df_accel_filter) %in% xyz_columns],
class = as.factor(df_accel_filter$type))
selected_columns = c("xyz_mean", "xyz_PSD_1", "xyz_PSD_3", "xyz_PSD_6", "xyz_PSD_10", "class")
train_data = df_accel_candidate[, selected_columns]
mod = svm(class ~., data = train_data, kernel = "radial", cost = 100, gamma = 4, scale = FALSE)
users = unique(df_accel_by_hour_xyz_all$user)
probability_of_pd = vector(length=length(users))
predict_result = vector(length=length(users))
actual_result = vector(length=length(users))
for (i in 1:length(users)) {
print(users[i])
#predict_user_index = df_accel_by_hour_xyz_all$user == users[i]
predict_user_index = df_accel_filter$user == users[i]
train_data = df_accel_candidate[!predict_user_index, selected_columns]
test_data = df_accel_candidate[predict_user_index, selected_columns]
mod = svm(class ~., data = train_data, kernel = "radial", cost = 100, gamma = 4, scale = FALSE)
record_pred = predict(mod, test_data)
single_user_probability_of_pd = mean(record_pred == "PD")
single_user_predict_result = ifelse(single_user_probability_of_pd > 0.5, "PD", "Control")
print(single_user_predict_result)
probability_of_pd[i] = single_user_probability_of_pd
predict_result[i] = single_user_predict_result
actual_result[i] = unique(as.character(df_accel_candidate$class[predict_user_index]))
print(table(record_pred, df_accel_candidate[predict_user_index, ]$class))
}
f_accuracy(predict_result, actual_result)
data.frame(users, probability_of_pd, predict_result, actual_result)
View(df_accel_filter)
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(),
user="mark", password="mark",
dbname="test", host="54.191.65.138")
dbWriteTable(con, "my_accel", data.frame(df_accel_filter), append = TRUE )
on.exit(dbDisconnect(con))
library(plumber)
setwd("/Users/longnguyen/Documents/295/neuro-analytics/predictive_server")
r <- plumb("endpoint.R")
r$run(port=8000)
View(df_accel_filter)
library(RMySQL)
library(MASS)
library(e1071)
setwd("/Users/longnguyen/Documents/295/neuro-analytics/predictive_server")
model_dir = "model"
